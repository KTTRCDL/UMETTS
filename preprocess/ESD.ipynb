{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for ESD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "PROJECT_PATH = os.path.join('/', *os.getcwd().split(os.sep)[:-1])\n",
    "\n",
    "# ESD raw data path, e.g. data/ESD\n",
    "ESD_RAW_PATH = f'{PROJECT_PATH}/data/ESD'\n",
    "# ESD (english) raw data folders, e.g. data/ESD/0011\n",
    "ESD_RAW_EN_PATHS = [f'{ESD_RAW_PATH}/00{f}' for f in range(11, 21)]\n",
    "\n",
    "# Copy ESD raw data to ESD (english) raw data folder, e.g. data/ESD_EN\n",
    "ESD_EN_PATH = f'{PROJECT_PATH}/data/ESD_EN'\n",
    "\n",
    "# Copy and split ESD (english) raw data by speaker folder for MFA, e.g. data/ESD_EN_MFA\n",
    "ESD_EN_MFA = f'{PROJECT_PATH}/data/ESD_EN_MFA'\n",
    "\n",
    "# preprocessed MFA data, e.g. data/ESD_EN_MFA_preprocessed\n",
    "ESD_EN_MFA_PREPRO = f'{PROJECT_PATH}/data/ESD_EN_MFA_preprocessed'\n",
    "\n",
    "# filelist path for load ESD (english) data for training, validation and testing, e.g. EMITTS/filelist/ESD\n",
    "FILELIST_PATH = f'{PROJECT_PATH}/EMITTS/filelist/ESD'\n",
    "os.makedirs(FILELIST_PATH, exist_ok=True)\n",
    "\n",
    "# EMO_FEATURE_SAVE_PATH is the path to save the extracted emotion features, e.g. EPAlign/mmefeature/ESD\n",
    "EMO_FEATURE_SAVE_PATH = f\"{PROJECT_PATH}/EPAlign/mmefeature/ESD\"\n",
    "\n",
    "# find all the wav files\n",
    "def find_file(path, suffix):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name.endswith(suffix):\n",
    "                result.append(os.path.join(root, name))\n",
    "    return result\n",
    "\n",
    "def load_filelist(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        filelist = [line.strip().split(split) for line in f]\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy ESD english data into ESD_EN_PATH\n",
    "os.system(f'mkdir -p {ESD_EN_PATH}')\n",
    "for path in ESD_RAW_EN_PATHS:\n",
    "    os.system(f'cp -r {path} {ESD_EN_PATH}')\n",
    "    print(f'Copied {path} to {ESD_EN_PATH}')\n",
    "\n",
    "wav_files = find_file(ESD_EN_PATH, '.wav')\n",
    "wav_dict = {}\n",
    "for wav_file in wav_files:\n",
    "    wav_dict[wav_file.split('/')[-1][:-4]] = wav_file\n",
    "\n",
    "assert len(wav_dict) == 17_500\n",
    "\n",
    "df_total = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "for file in find_file(ESD_EN_PATH, '.txt'):\n",
    "    # print(file)\n",
    "    filename_text_emtiontag = load_filelist(file, split='\\t')\n",
    "    df = pd.DataFrame(filename_text_emtiontag, columns=['filename', 'text', 'emotiontag'])\n",
    "    df_total = pd.concat([df_total, df])\n",
    "\n",
    "emotion_tags = ['Angry', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "train_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "val_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "test_df = pd.DataFrame(columns=['filename', 'text', 'emotiontag'])\n",
    "\n",
    "for emotion_tag in emotion_tags:\n",
    "    df_e = df_total[df_total['emotiontag'] == emotion_tag].to_numpy()\n",
    "    # split the data into train, val, test with 80%, 10%, 10%\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(df_e)\n",
    "    df_tr = pd.DataFrame(df_e[:int(len(df_e)*0.8)], columns=['filename', 'text', 'emotiontag'])\n",
    "    df_va = pd.DataFrame(df_e[int(len(df_e)*0.8):int(len(df_e)*0.9)], columns=['filename', 'text', 'emotiontag'])\n",
    "    df_te = pd.DataFrame(df_e[int(len(df_e)*0.9):], columns=['filename', 'text', 'emotiontag'])\n",
    "    train_df = pd.concat([train_df, df_tr])\n",
    "    val_df = pd.concat([val_df, df_va])\n",
    "    test_df = pd.concat([test_df, df_te])\n",
    "\n",
    "assert len(train_df) == 14_000\n",
    "assert len(val_df) == 1_750\n",
    "assert len(test_df) == 1_750\n",
    "\n",
    "# save train, val, test filelist\n",
    "train_val_test = [\"train\", \"val\", \"test\"]\n",
    "dfs = [train_df, val_df, test_df]\n",
    "for i, df in enumerate(dfs):\n",
    "    new_filelist = f'{FILELIST_PATH}/esd_en_audio_sid_text_efeature_{train_val_test[i]}_filelist.txt'\n",
    "    with open(new_filelist, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            wav_path = wav_dict[row['filename']]\n",
    "            sid = int(row['filename'].split('_')[0]) - 10\n",
    "            text = row['text']\n",
    "            mmefeature_path = f'{EMO_FEATURE_SAVE_PATH}/{row['emotiontag'].lower()}.pt'\n",
    "            f.write(f'{wav_path}|{str(sid)}|{text}|{mmefeature_path}\\n')\n",
    "    print(f'Saved {new_filelist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text for VITS Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f'{PROJECT_PATH}/EMITTS/VITS')\n",
    "import utils.text_utils as text\n",
    "\n",
    "# test_text = test_df['text'].to_list()\n",
    "# train_text = train_df['text'].to_list()\n",
    "\n",
    "# t = text._clean_text(test_text, [\"english_cleaners2\"])\n",
    "\n",
    "# save train, val, test clean text filelist\n",
    "train_val_test = [\"train\", \"val\", \"test\"]\n",
    "dfs = [train_df, val_df, test_df]\n",
    "for i, df in enumerate(dfs):\n",
    "    new_filelist = f'{FILELIST_PATH}/esd_en_audio_sid_text_efeature_{train_val_test[i]}_filelist.txt.cleaned'\n",
    "    clean_texts = text._clean_text(df['text'].to_list(), [\"english_cleaners2\"])\n",
    "    with open(new_filelist, 'w', encoding='utf-8') as f:\n",
    "        for index, row in df.iterrows():\n",
    "            wav_path = wav_dict[row['filename']]\n",
    "            sid = int(row['filename'].split('_')[0]) - 10\n",
    "            clean_text = clean_texts[index]\n",
    "            mmefeature_path = f'{EMO_FEATURE_SAVE_PATH}/{row['emotiontag'].lower()}.pt'\n",
    "            f.write(f'{wav_path}|{str(sid)}|{clean_text}|{mmefeature_path}\\n')\n",
    "    print(f'Saved {new_filelist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text for FastSpeech2 Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/en/latest/) (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
    "\n",
    "The following steps are used to align the utterances and the phoneme sequences refer to the [mfa-ljspeech.ipynb](https://gist.github.com/12264d15afad861cb897f7a20a01762e.git):\n",
    "\n",
    "1. install using [mamba](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html#)\n",
    "    ```bash\n",
    "    # create and install\n",
    "    mamba create -n aligner -c conda-forge montreal-forced-aligner\n",
    "\n",
    "    # install \n",
    "    mamba install -c conda-forge montreal-forced-aligner\n",
    "    ```\n",
    "\n",
    "2. download and modify the pre-trained model and the lexicon (current working directory is the root of the project)\n",
    "    ```bash\n",
    "    mamba activate aligner\n",
    "    wget -O ./data/english.zip https://github.com/MontrealCorpusTools/mfa-models/raw/main/acoustic/english.zip\n",
    "    wget -O ./data/librispeech-lexicon.txt http://www.openslr.org/resources/11/librispeech-lexicon.txt\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/pull/480\n",
    "import re\n",
    "lexicon = open(f\"{PROJECT_PATH}/data/librispeech-lexicon.txt\").readlines()\n",
    "sp = re.compile(r\"\\s+\")\n",
    "with open(f\"{PROJECT_PATH}/data/modified_lexicon.txt\", \"w\") as f:\n",
    "    for line in lexicon:\n",
    "        word, *phonemes = sp.split(line.strip())\n",
    "        phonemes = \" \".join(phonemes)\n",
    "        f.write(f\"{word}\\t{phonemes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. prepare ESD_EN_SP data (split the data with speaker id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(ESD_EN_MFA, exist_ok=True)\n",
    "\n",
    "for path in ESD_RAW_EN_PATHS:\n",
    "    speaker = path.split('/')[-1]\n",
    "    os.system(f'mkdir -p {ESD_EN_MFA}/{speaker}')\n",
    "    wav_paths = find_file(path, '.wav')\n",
    "    for wav_path in wav_paths:\n",
    "        os.system(f'cp {wav_path} {ESD_EN_MFA}/{speaker}')\n",
    "    print(f'Copied all .wav files from {path} to {ESD_EN_MFA}/{speaker}')\n",
    "\n",
    "for file in find_file(ESD_EN_PATH, '.txt'):\n",
    "    # print(file)\n",
    "    filename_text_emtiontag = load_filelist(file, split='\\t')\n",
    "    for filename, text, _ in filename_text_emtiontag:\n",
    "        with open(f'{ESD_EN_MFA}/{filename.split(\"_\")[0]}/{filename}.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. using MFA to align the utterances and the phoneme sequences (current working directory is the root of the project)\n",
    "    ```bash\n",
    "    mfa align -t ./data/mfa_temp -j 10 ./data/ESD_EN_MFA ./data/modified_lexicon.txt ./data/english.zip ./data/ESD_EN_MFA\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in ESD_RAW_EN_PATHS:\n",
    "    speaker = path.split('/')[-1]\n",
    "    os.system(f'mv {ESD_EN_MFA}/{speaker}/* {ESD_EN_MFA}')\n",
    "    os.system(f'rm -r {ESD_EN_MFA}/{speaker}')\n",
    "    print(f'Moved all files from {ESD_EN_MFA}/{speaker} to {ESD_EN_MFA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from EMITTS.FastSpeech2.config.config import TrainConfig\n",
    "sys.path.append(f'{PROJECT_PATH}/EMITTS/FastSpeech2')\n",
    "from EMITTS.FastSpeech2.src.preprocess.preprocess import Preprocessor\n",
    "cfg = TrainConfig()\n",
    "\n",
    "cfg.raw_data_path = ESD_EN_MFA\n",
    "cfg.train_ids_path = f'{FILELIST_PATH}/esd_en_audio_sid_text_efeature_train_filelist.txt'\n",
    "cfg.val_ids_path = f'{FILELIST_PATH}/esd_en_audio_sid_text_efeature_val_filelist.txt'\n",
    "cfg.test_ids_path = f'{FILELIST_PATH}/esd_en_audio_sid_text_efeature_test_filelist.txt'\n",
    "cfg.preprocessed_data_path = ESD_EN_MFA_PREPRO\n",
    "\n",
    "preprocessor = Preprocessor(cfg)\n",
    "preprocessor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMTTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
